{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLNr8HkePJxfmLix85Hqii",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhilesh-075/Machine-Learning/blob/main/ID3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qth8ds72jcyp",
        "outputId": "9909b6bf-d001-41e5-9943-ca1841c96d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Building Decision Tree ---\n",
            "\n",
            "Current Entropy: 1.0000\n",
            "Info Gain for 'Outlook': 0.5409\n",
            "Info Gain for 'Temperature': 0.2075\n",
            "Best Feature: Outlook\n",
            "Branch: Outlook = Sunny\n",
            "  Leaf: No\n",
            "Branch: Outlook = Overcast\n",
            "  Leaf: Yes\n",
            "Branch: Outlook = Rain\n",
            "  Current Entropy: 0.9183\n",
            "  Info Gain for 'Temperature': 0.2516\n",
            "  Best Feature: Temperature\n",
            "  Branch: Temperature = Mild\n",
            "    Leaf: Yes\n",
            "  Branch: Temperature = Cool\n",
            "    Leaf (majority): Yes\n",
            "\n",
            "--- Final Decision Tree ---\n",
            "Outlook = Sunny:\n",
            "  --> No\n",
            "Outlook = Overcast:\n",
            "  --> Yes\n",
            "Outlook = Rain:\n",
            "  Temperature = Mild:\n",
            "    --> Yes\n",
            "  Temperature = Cool:\n",
            "    --> Yes\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "def entropy(labels):\n",
        "    total = len(labels)\n",
        "    counts = Counter(labels)\n",
        "    ent = 0.0\n",
        "    for label in counts:\n",
        "        p = counts[label] / total\n",
        "        ent -= p * math.log2(p)\n",
        "    return ent\n",
        "\n",
        "def information_gain(parent_labels, subsets):\n",
        "    parent_entropy = entropy(parent_labels)\n",
        "    total = len(parent_labels)\n",
        "    weighted_entropy = sum((len(subset) / total) * entropy(subset) for subset in subsets)\n",
        "    gain = parent_entropy - weighted_entropy\n",
        "    return gain\n",
        "\n",
        "def split_dataset(features, labels, feature_values):\n",
        "    split = {}\n",
        "    for value in feature_values:\n",
        "        split[value] = [labels[i] for i in range(len(features)) if features[i] == value]\n",
        "    return split\n",
        "\n",
        "def unique_values(column):\n",
        "    return list(set(column))\n",
        "\n",
        "def id3(data, labels, features, depth=0):\n",
        "    # If all labels are the same, return that label\n",
        "    if labels.count(labels[0]) == len(labels):\n",
        "        print(\"  \" * depth + f\"Leaf: {labels[0]}\")\n",
        "        return labels[0]\n",
        "\n",
        "    # If no more features, return majority label\n",
        "    if not features:\n",
        "        majority = Counter(labels).most_common(1)[0][0]\n",
        "        print(\"  \" * depth + f\"Leaf (majority): {majority}\")\n",
        "        return majority\n",
        "\n",
        "    # Calculate information gain for each feature\n",
        "    base_entropy = entropy(labels)\n",
        "    print(f\"{'  ' * depth}Current Entropy: {base_entropy:.4f}\")\n",
        "    gains = []\n",
        "    for feature in features:\n",
        "        values = unique_values(data[feature])\n",
        "        subsets = [[labels[i] for i in range(len(labels)) if data[feature][i] == value] for value in values]\n",
        "        gain = information_gain(labels, subsets)\n",
        "        gains.append((gain, feature))\n",
        "        print(f\"{'  ' * depth}Info Gain for '{feature}': {gain:.4f}\")\n",
        "\n",
        "    # Choose best feature\n",
        "    best_gain, best_feature = max(gains, key=lambda x: x[0])\n",
        "    print(\"  \" * depth + f\"Best Feature: {best_feature}\")\n",
        "\n",
        "    tree = {best_feature: {}}\n",
        "    values = unique_values(data[best_feature])\n",
        "    for value in values:\n",
        "        # Create subset of data\n",
        "        sub_data = {}\n",
        "        sub_labels = []\n",
        "        for f in features:\n",
        "            if f == best_feature:\n",
        "                continue\n",
        "            sub_data[f] = [data[f][i] for i in range(len(data[best_feature])) if data[best_feature][i] == value]\n",
        "        sub_labels = [labels[i] for i in range(len(labels)) if data[best_feature][i] == value]\n",
        "\n",
        "        print(\"  \" * depth + f\"Branch: {best_feature} = {value}\")\n",
        "        subtree = id3(sub_data, sub_labels, [f for f in features if f != best_feature], depth + 1)\n",
        "        tree[best_feature][value] = subtree\n",
        "\n",
        "    return tree\n",
        "\n",
        "def print_tree(tree, indent=\"\"):\n",
        "    if isinstance(tree, dict):\n",
        "        for key, branches in tree.items():\n",
        "            for val, subtree in branches.items():\n",
        "                print(indent + f\"{key} = {val}:\")\n",
        "                print_tree(subtree, indent + \"  \")\n",
        "    else:\n",
        "        print(indent + f\"--> {tree}\")\n",
        "\n",
        "# Sample data\n",
        "Outlook = [\"Sunny\", \"Sunny\", \"Overcast\", \"Rain\", \"Rain\", \"Rain\"]\n",
        "Temperature = [\"Hot\", \"Hot\", \"Hot\", \"Mild\", \"Cool\", \"Cool\"]\n",
        "PlayTennis = [\"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\"]\n",
        "\n",
        "# Prepare dataset\n",
        "dataset = {\n",
        "    \"Outlook\": Outlook,\n",
        "    \"Temperature\": Temperature\n",
        "}\n",
        "features = list(dataset.keys())\n",
        "\n",
        "# Run ID3\n",
        "print(\"\\n--- Building Decision Tree ---\\n\")\n",
        "decision_tree = id3(dataset, PlayTennis, features)\n",
        "\n",
        "print(\"\\n--- Final Decision Tree ---\")\n",
        "print_tree(decision_tree)\n"
      ]
    }
  ]
}