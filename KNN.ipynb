{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuy9rR6t+PbRS0dVlvW1ID",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhilesh-075/6thSem-ML-Lab/blob/main/KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGBxmRB80yko",
        "outputId": "65e09099-6473-4cb4-e909-6cbcd31289f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 96.67%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# 1. Load the dataset (using Iris dataset as an example)\n",
        "def load_iris_data():\n",
        "    from sklearn.datasets import load_iris\n",
        "    data = load_iris()\n",
        "    X = data.data\n",
        "    y = data.target\n",
        "    return X, y\n",
        "\n",
        "# 2. Calculate Euclidean distance between two points\n",
        "def euclidean_distance(point1, point2):\n",
        "    return np.sqrt(np.sum((point1 - point2) ** 2))\n",
        "\n",
        "# 3. KNN Algorithm - Predict a label for a single data point\n",
        "def knn_predict(X_train, y_train, test_point, k=3):\n",
        "    # Step 1: Calculate the distance between the test point and all training points\n",
        "    distances = [euclidean_distance(test_point, x_train) for x_train in X_train]\n",
        "\n",
        "    # Step 2: Sort by distance and return indices of the first k neighbors\n",
        "    k_indices = np.argsort(distances)[:k]\n",
        "\n",
        "    # Step 3: Get the labels of the k nearest neighbors\n",
        "    k_nearest_labels = [y_train[i] for i in k_indices]\n",
        "\n",
        "    # Step 4: Return the most common class label among the k neighbors\n",
        "    most_common = Counter(k_nearest_labels).most_common(1)\n",
        "    return most_common[0][0]\n",
        "\n",
        "# 4. KNN Algorithm - Predict labels for all test points\n",
        "def knn_predict_all(X_train, y_train, X_test, k=3):\n",
        "    predictions = [knn_predict(X_train, y_train, test_point, k) for test_point in X_test]\n",
        "    return predictions\n",
        "\n",
        "# 5. Evaluate the accuracy of the model\n",
        "def evaluate_model(X_train, y_train, X_test, y_test, k=3):\n",
        "    predictions = knn_predict_all(X_train, y_train, X_test, k)\n",
        "    accuracy = np.mean(predictions == y_test)\n",
        "    return accuracy\n",
        "\n",
        "# 6. Split the data into training and testing sets\n",
        "def train_test_split(X, y, test_size=0.2):\n",
        "    # Calculate the number of test samples\n",
        "    num_test_samples = int(len(X) * test_size)\n",
        "\n",
        "    # Shuffle the dataset indices\n",
        "    indices = np.random.permutation(len(X))\n",
        "\n",
        "    # Split the data into train and test\n",
        "    X_train, X_test = X[indices[num_test_samples:]], X[indices[:num_test_samples]]\n",
        "    y_train, y_test = y[indices[num_test_samples:]], y[indices[:num_test_samples]]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# 7. Example of usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load data\n",
        "    X, y = load_iris_data()\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = evaluate_model(X_train, y_train, X_test, y_test, k=3)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ]
    }
  ]
}